{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "# problem_type = 'regression'\n",
    "# problem_type = 'classification'\n",
    "\n",
    "# if problem_type == 'regression':\n",
    "#     task_name = 'brain age'\n",
    "ENV_VARS = dotenv_values('.env')\n",
    "DPATH_RESULTS = Path(ENV_VARS['DPATH_FL_RESULTS'])\n",
    "DPATH_FIGS = Path(ENV_VARS['DPATH_FL_FIGS'])\n",
    "fpath_results_ba = DPATH_RESULTS / 'results-regression-age-sex-hc-aseg-5-3791.tsv'\n",
    "# elif problem_type == 'classification':\n",
    "#     task_name = 'cognitive decline'\n",
    "fpath_results_cog = DPATH_RESULTS / 'results-classification-decline-age-case-aparc-5-3791.tsv'\n",
    "# else:\n",
    "#     raise ValueError(f'Unknown problem_type: {problem_type}')\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "DATASET_COLOUR_MAP = {\n",
    "    'PPMI': '#D0A441',\n",
    "    'ADNI': '#0CA789',\n",
    "    'QPN': '#A6A6C6',\n",
    "}\n",
    "\n",
    "df_results = pd.concat(\n",
    "    [\n",
    "        # pd.read_csv(fpath_results_ba, sep='\\t'),\n",
    "        pd.read_csv(fpath_results_cog, sep='\\t'),\n",
    "    ],\n",
    "    axis='index',\n",
    ")\n",
    "df_results = df_results.query('method != \"fl_voting\" and (metric == \"balanced_accuracy\" or metric == \"mean_absolute_error\")')\n",
    "# df_results = df_results.query('method != \"fl_voting\" and test_dataset != \"all\" and (metric == \"balanced_accuracy\" or metric == \"r2\")')\n",
    "df_results['method'] = df_results['method'].map({'silo': 'Siloed', 'mega': 'Mega-analysis', 'fl_fedavg': 'Federated'})\n",
    "df_results['test_dataset'] = df_results['test_dataset'].str.upper()\n",
    "df_results = df_results.reset_index(drop=True)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_results_null = df_results.query('is_null == True')\n",
    "\n",
    "# dataset = 'ADNI'\n",
    "# df_results_null.query(f'test_dataset == \"{dataset}\"').groupby(['method', 'metric'])['score'].describe()\n",
    "\n",
    "# for metric, df in df_results_null.groupby('metric'):\n",
    "#     print(df_results_null.query(f'metric == \"{metric}\"').describe())\n",
    "#     print(f'===== {metric.upper()} =====')\n",
    "#     df = df.groupby(['method', 'test_dataset'])\n",
    "#     # print(df['score'].max())\n",
    "#     print(df['score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df_results_null = df_results.query('is_null == True and test_dataset != \"ALL\"')\n",
    "df_results_nonnull = df_results.query('is_null == False and test_dataset != \"ALL\"')\n",
    "df_results_all = df_results.query('test_dataset == \"ALL\"')\n",
    "\n",
    "\n",
    "bar_width = 0.8\n",
    "null_width = 0.8\n",
    "\n",
    "grid = sns.catplot(\n",
    "    data=df_results_nonnull,\n",
    "    x='method',\n",
    "    y='score',\n",
    "    hue='test_dataset',\n",
    "    row='metric',\n",
    "    kind='bar',\n",
    "    errorbar='sd',\n",
    "    order=['Siloed', 'Federated', 'Mega-analysis'],\n",
    "    height=2.5,\n",
    "    aspect=3,\n",
    "    width=bar_width,\n",
    "    sharex=False,\n",
    "    sharey=False,\n",
    "    palette=DATASET_COLOUR_MAP,\n",
    "    alpha=0.8,\n",
    "    saturation=1,\n",
    ")    \n",
    "\n",
    "for i_ax, (metric, ax) in enumerate(grid.axes_dict.items()):\n",
    "\n",
    "    task_name = {'balanced_accuracy': 'cognitive decline', 'mean_absolute_error': 'brain age', 'r2': 'brain age'}[metric]\n",
    "    print(f'===== {task_name.upper()} =====')\n",
    "\n",
    "    ax.text(-0.08, 1.05, 'ABCDE'[i_ax], transform=ax.transAxes, size=16, weight='bold')\n",
    "\n",
    "    for xticklabel, xtick in zip(ax.get_xticklabels(), ax.get_xticks()):\n",
    "\n",
    "        method = xticklabel.get_text()\n",
    "        df_mean_null_values = df_results_null.query(f'metric == @metric').groupby(['method', 'test_dataset'])['score'].describe()\n",
    "        df_mean_all_values = df_results_all.query(f'metric == @metric').groupby(['method', 'test_dataset'])['score'].describe()\n",
    "\n",
    "        if method in ['Siloed', 'Federated', 'Mega-analysis']:\n",
    "            mean_null_values = df_mean_null_values.loc['Siloed', 'mean']\n",
    "            mean_all_values = df_mean_all_values.loc[method, 'mean'].item()\n",
    "        # elif xticklabel.get_text() == 'Mega-analysis':\n",
    "        #     mean_null_values = df_mean_null_values.loc['Mega-analysis', 'mean']\n",
    "        else:\n",
    "            raise ValueError(f'Unknown method: {method}')\n",
    "\n",
    "        print(f'----- {method.capitalize()} -----')\n",
    "        print('MEAN NULL')\n",
    "        print(mean_null_values)\n",
    "        print('MEAN All')\n",
    "        print(mean_all_values)\n",
    "\n",
    "        if metric == 'mean_absolute_error':\n",
    "            best_null_value = mean_null_values.min()\n",
    "        else:\n",
    "            best_null_value = mean_null_values.max()\n",
    "\n",
    "        # ax.plot([xtick - null_width/2, xtick + null_width/2], [best_null_value, best_null_value], 'k--', alpha=0.5)\n",
    "        ax.plot([xtick - null_width/2, xtick + null_width/2], [mean_all_values, mean_all_values], 'r:', alpha=0.75)\n",
    "    ax.axhline(best_null_value, color='k', linestyle='--', alpha=0.5)\n",
    "\n",
    "    # ax.set_ylabel('')\n",
    "    # ax.set_title(f\"{metric.capitalize().replace('_', ' ')} for {task_name} task\")\n",
    "    ax.set_ylabel(metric.capitalize().replace('_', ' '))\n",
    "    ax.set_title(f\"{task_name.capitalize()} task\")\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    if metric == 'mean_absolute_error':\n",
    "        arrowstyle = '->'\n",
    "    else:\n",
    "        arrowstyle = '<-'\n",
    "    \n",
    "    ax.annotate(\n",
    "        '', xy=(1.05, 0.25), xycoords='axes fraction', xytext=(1.05, 0.75), \n",
    "        arrowprops=dict(arrowstyle=arrowstyle, linewidth=2, mutation_scale=20))\n",
    "    ax.annotate(\n",
    "        'Better\\nmodel', xy=(1.1, 0.5), xycoords='axes fraction', ha='center', va='center',\n",
    "    )\n",
    "\n",
    "grid.legend.set_title('Test dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'QPN'\n",
    "df_results_nonnull.query(f'test_dataset == \"{dataset}\"').groupby(['method', 'metric'])['score'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DPATH_FIGS.mkdir(exist_ok=True)\n",
    "\n",
    "fpath_fig = DPATH_FIGS / f'metrics-combined.png'\n",
    "# grid.savefig(fpath_fig, dpi=300)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl-pd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
